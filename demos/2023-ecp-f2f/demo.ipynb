{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfba5cdb-f769-4d04-90cd-c8ec30be08a6",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Demonstrator 2023-ecp-f2f\n",
    "\n",
    "Refer to `README.md` for installation instructions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14bc2771-56c5-4980-a272-820c96d0b825",
   "metadata": {},
   "source": [
    "## 0. Configuration\n",
    "\n",
    "Let's start off by sourcing secrets and defining the locations of the various required services:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cad8b4b-f59e-4f65-bf0d-8645309ee4ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# source secrets\n",
    "source .env"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3869795-9bf5-4642-ba13-020c05e26170",
   "metadata": {},
   "source": [
    "#### **List TES instances**\n",
    "\n",
    "Let's see what TES instances we have defined:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68fe37d-05cc-4a54-8a67-3a6c01e5ad8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "unset TES_INSTANCES\n",
    "declare -A TES_INSTANCES\n",
    "while IFS=',' read -r KEY URL; do\n",
    "    TES_INSTANCES[\"$KEY\"]=$URL\n",
    "done < .tes_instances\n",
    "\n",
    "for key in \"${!TES_INSTANCES[@]}\"; do\n",
    "    export TES=\"${TES_INSTANCES[$key]}\"\n",
    "    echo \"$key: $TES\"\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e23aef-442c-4bc9-ad40-d8e95d07e720",
   "metadata": {},
   "source": [
    "If you are running the demo on the ELIXIR Cloud infrastructure, the demo\n",
    "makes use of the following TES and cloud storage deployments.\n",
    "\n",
    "**Figure 0. ELIXIR Cloud deployments.**\n",
    "\n",
    "![Figure 0](images/figure_0.svg)\n",
    "\n",
    "> This setup will of course differ if you deployed your own nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381e3335-a343-4504-9799-c8d5f1b5a4d6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. Executing tasks via the GA4GH TES API\n",
    "\n",
    "In this section, we will use both the shell and a dedicated Python library to\n",
    "send tasks to the defined TES instances."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6780fb81-0d37-43fb-8aa4-a2a3a80069b2",
   "metadata": {},
   "source": [
    "### Using the shell\n",
    "\n",
    "Here, we will use the `curl` library to send requests to the TES APIs. It\n",
    "should be easy to adapt the calls for use with other tools, such as Postman or\n",
    "your favorite progamming language's HTTP request libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38fe7c4-d146-479b-afd9-a7716a421e4a",
   "metadata": {},
   "source": [
    "#### **Running a minimal task**\n",
    "\n",
    "Now we will submit a very simple task to each of these instances (Figure 1A).\n",
    "\n",
    "**Figure 1A. Executing a minimal task.**\n",
    "\n",
    "![Figure 1A](images/figure_1A.svg)\n",
    "\n",
    "The task we use here defines no inputs and outputs, so we do not need to read\n",
    "from or write to any storage instances.\n",
    "\n",
    "The payload for the task needs to be provided in JSON format. Nicely formatted,\n",
    "it looks like this:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"executors\": [\n",
    "    {\n",
    "      \"image\": \"alpine\",\n",
    "      \"command\": [\n",
    "        \"echo\",\n",
    "        \"hello\"\n",
    "      ]\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "```\n",
    "\n",
    "With these instructions, we are asking the TES instances to execute the command\n",
    "`echo hello` in (the default version of) an Alpine Linux container.\n",
    "\n",
    "Let's minify the JSON payload and assign it to a variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010e6343-a8b8-44ee-afb5-c3ce25f2293e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "export PAYLOAD='{\"executors\":[{\"image\":\"alpine\",\"command\":[\"echo\",\"hello\"]}]}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72916da9-1de2-4665-8be6-24f2636af0fe",
   "metadata": {},
   "source": [
    "Now we are ready to submit the tasks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8186fe6e-ecf7-4856-b421-7a3c9aa45e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "unset TASKS\n",
    "declare -A TASKS\n",
    "for key in \"${!TES_INSTANCES[@]}\"; do\n",
    "    export TES=\"${TES_INSTANCES[$key]}\"\n",
    "    echo \"Submitting task to $key ($TES)...\"\n",
    "    TASK_ID=$( \\\n",
    "        curl \\\n",
    "            --silent \\\n",
    "            --request \"POST\" \\\n",
    "            --header \"accept: application/json\" \\\n",
    "            --header \"Content-Type: application/json\" \\\n",
    "            --user \"${FUNNEL_SERVER_USER}:${FUNNEL_SERVER_PASSWORD}\" \\\n",
    "            --data \"$PAYLOAD\" \\\n",
    "            \"${TES%/}/v1/tasks\" | \\\n",
    "        jq \".id\" - | \\\n",
    "        tr -d '\"'\n",
    "    )\n",
    "    if [ $TASK_ID == \"null\" ]; then\n",
    "        echo \"FAILED\"\n",
    "    else\n",
    "        echo \"Task ID: $TASK_ID\"\n",
    "        TASKS[\"$TASK_ID\"]=\"$TES\"\n",
    "    fi\n",
    "    echo \"================================================================================\"\n",
    "done\n",
    "echo \"DONE\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fbf53cf-de1e-43e4-920d-ca52dff6b29e",
   "metadata": {},
   "source": [
    "Let's see how the execution of successfully submitted tasks is progressing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce17adf7-88a6-4738-9f1f-b6d243010fbb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for TASK_ID in \"${!TASKS[@]}\"; do\n",
    "    export TES=\"${TASKS[$TASK_ID]}\"\n",
    "    echo \"Checking state of task '$TASK_ID' ($TES)...\"\n",
    "    RESPONSE=$( \\\n",
    "        curl \\\n",
    "            --silent \\\n",
    "            --request \"GET\" \\\n",
    "            --header \"accept: application/json\" \\\n",
    "            --header \"Content-Type: application/json\" \\\n",
    "            --user \"${FUNNEL_SERVER_USER}:${FUNNEL_SERVER_PASSWORD}\" \\\n",
    "            \"${TES%/}/v1/tasks/${TASK_ID}\" \\\n",
    "    )\n",
    "    echo -n \"Task State: \"\n",
    "    echo $RESPONSE | jq \".state\"\n",
    "    echo \"================================================================================\"\n",
    "done\n",
    "echo \"DONE\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e120ede-9fd7-4cee-b58e-ef7a1b1fd7e7",
   "metadata": {},
   "source": [
    "#### **Running a task with inputs and outputs**\n",
    "\n",
    "Let's try a little more realistic task with an input (from the web) and an\n",
    "output (written to an FTP instance), as depicted in Figure 1B.\n",
    "\n",
    "**Figure 1B. Data flow for TES execution.** TES calls are as in Figure 1A and\n",
    "have been omitted for clarity.\n",
    "\n",
    "![Figure 1B](images/figure_1B.svg)\n",
    "\n",
    "We define the following payload:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"name\": \"md5sum\",\n",
    "  \"description\": \"calculate md5sum of input file and write to output file\",\n",
    "  \"tags\": {\n",
    "    \"project\": \"2023-ecp-f2f Demonstrator\",\n",
    "    \"project_owner\": \"ELIXIR Cloud & AAI\"\n",
    "  },\n",
    "  \"executors\": [\n",
    "    {\n",
    "      \"command\": [\n",
    "        \"md5sum\",\n",
    "        \"/data/input\"\n",
    "      ],\n",
    "      \"image\": \"alpine\",\n",
    "      \"stdout\": \"/data/output\",\n",
    "      \"workdir\": \"/data\"\n",
    "    }\n",
    "  ],\n",
    "  \"inputs\": [\n",
    "    {\n",
    "      \"url\": \"{{INPUT_FILE}}\",\n",
    "      \"path\": \"/data/input\"\n",
    "    }\n",
    "  ],\n",
    "  \"outputs\": [\n",
    "    {\n",
    "      \"path\": \"/data/output\",\n",
    "      \"url\": \"{{FTP_INSTANCE}}/2023-ecp-f2f/md5sum\",\n",
    "      \"type\": \"FILE\"\n",
    "    }\n",
    "  ],\n",
    "  \"resources\": {\n",
    "    \"cpu_cores\": 1,\n",
    "    \"disk_gb\": 1,\n",
    "    \"preemptible\": false,\n",
    "    \"ram_gb\": 1\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "As you can see, here we determine the MD5 sum of an input file, write it to an\n",
    "output file inside the container, and finally copy it over to an FTP server.\n",
    "\n",
    "Let's minify that and replace the placeholders `{{INPUT_FILE}}` and\n",
    "`{{FTP_INSTANCE}}` with some actual values.\n",
    "\n",
    "> Note that because Funnel does currently only allow [passing FTP storage\n",
    "> credentials via the FTP\n",
    "> URL](https://ohsu-comp-bio.github.io/funnel/docs/storage/ftp/) and TESK does\n",
    "> not support FTP URLs with credentials, we need to use different payloads for\n",
    "> the two services!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1454c4e4-7ed2-42d3-aa38-379788d120c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PAYLOAD_RAW='{\"name\":\"md5sum\",\"description\":\"calculate md5sum of input file and write to output file\",\"tags\":{\"project\":\"2023-ecp-f2f Demonstrator\",\"project_owner\":\"ELIXIR Cloud & AAI\"},\"executors\":[{\"command\":[\"md5sum\",\"/data/input\"],\"image\":\"alpine\",\"stdout\":\"/data/output\",\"workdir\":\"/data\"}],\"inputs\":[{\"url\":\"{{INPUT_FILE}}\",\"path\":\"/data/input\"}],\"outputs\":[{\"path\":\"/data/output\",\"url\":\"{{FTP_INSTANCE}}/2023-ecp-f2f/md5sum\",\"type\":\"FILE\"}],\"resources\":{\"cpu_cores\":1,\"disk_gb\":1,\"preemptible\":false,\"ram_gb\":1}}'\n",
    "PAYLOAD_TMP=$(sed 's#{{INPUT_FILE}}#https://raw.githubusercontent.com/elixir-cloud-aai/elixir-cloud-demos/df5be391faf992ebcd5ec2b2aad581c99de26101/LICENSE#' <<< $PAYLOAD_RAW)\n",
    "export PAYLOAD_TESK=$(sed \"s|{{FTP_INSTANCE}}|${FTP_INSTANCE%/}|\" <<< $PAYLOAD_TMP)\n",
    "export PAYLOAD_FUNNEL=$(sed \"s|ftp://|ftp://${FTP_USER}:${FTP_PASSWORD}@|g\" <<< $PAYLOAD_TESK)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e6d2df-7c63-45b4-95c3-cff841d3bb8b",
   "metadata": {},
   "source": [
    "Let's submit as before (but setting the payload according to the service):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebd3294-f65d-47ee-8f97-099ef44fc32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "unset TASKS\n",
    "declare -A TASKS\n",
    "for key in \"${!TES_INSTANCES[@]}\"; do\n",
    "    export TES=\"${TES_INSTANCES[$key]}\"\n",
    "    if [[ $key =~ \"Funnel\" ]]; then\n",
    "        export PAYLOAD=\"$PAYLOAD_FUNNEL\"\n",
    "    else\n",
    "        export PAYLOAD=\"$PAYLOAD_TESK\"\n",
    "    fi\n",
    "    echo \"Submitting task to $key ($TES)...\"\n",
    "    TASK_ID=$( \\\n",
    "        curl \\\n",
    "            --silent \\\n",
    "            --request \"POST\" \\\n",
    "            --header \"accept: application/json\" \\\n",
    "            --header \"Content-Type: application/json\" \\\n",
    "            --user \"${FUNNEL_SERVER_USER}:${FUNNEL_SERVER_PASSWORD}\" \\\n",
    "            --data \"$PAYLOAD\" \\\n",
    "            \"${TES%/}/v1/tasks\" | \\\n",
    "        jq \".id\" - | \\\n",
    "        tr -d '\"'\n",
    "    )\n",
    "    if [ $TASK_ID == \"null\" ]; then\n",
    "        echo \"FAILED\"\n",
    "    else\n",
    "        echo \"Task ID: $TASK_ID\"\n",
    "        TASKS[\"$TASK_ID\"]=\"$TES\"\n",
    "    fi\n",
    "    echo \"================================================================================\"\n",
    "done\n",
    "echo \"DONE\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76cdfb98-7a8c-4cab-9270-33ec79d4549c",
   "metadata": {},
   "source": [
    "And check the states, but with a lot more detail:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21dbec3-ff97-454f-921c-39a971f14f11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "VIEW=BASIC\n",
    "for TASK_ID in \"${!TASKS[@]}\"; do\n",
    "    export TES=\"${TASKS[$TASK_ID]}\"\n",
    "    echo \"Checking state of task '$TASK_ID' ($TES)...\"\n",
    "    RESPONSE=$( \\\n",
    "        curl \\\n",
    "            --silent \\\n",
    "            --request \"GET\" \\\n",
    "            --header \"accept: application/json\" \\\n",
    "            --header \"Content-Type: application/json\" \\\n",
    "            --user \"${FUNNEL_SERVER_USER}:${FUNNEL_SERVER_PASSWORD}\" \\\n",
    "            \"${TES%/}/v1/tasks/${TASK_ID}?view=${VIEW}\" | \\\n",
    "        sed \"s/${FTP_USER}:${FTP_PASSWORD}@//g\"  # remove FTP credentials from logs\n",
    "    )\n",
    "    echo $RESPONSE | jq \".\"\n",
    "    echo \"================================================================================\"\n",
    "done\n",
    "echo \"DONE\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4127a9-c835-4611-a3f7-d19f9269345c",
   "metadata": {},
   "source": [
    "#### **Other TES operations**\n",
    "\n",
    "We have seen how we can submit tasks and get summary or detailed information on\n",
    "individual tasks.\n",
    "\n",
    "The full list of currently supported operations is:\n",
    "\n",
    "| HTTP Method | Endpoint | Description |\n",
    "| --- | --- | --- |\n",
    "| GET | `/service-info` | Fetch information about the service and its optional capabilities |\n",
    "| POST | `/tasks` | Create a task |\n",
    "| GET | `/tasks` | Fetch a list of all tasks |\n",
    "| GET | `/tasks/{task_id}` | Fetch details about a specific task |\n",
    "| POST | `/tasks/{task_id}:cancel` | Cancel a task |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6663d42f-5cf3-4d29-b8b9-e6bae65d1d2b",
   "metadata": {},
   "source": [
    "### Using the `py-tes` Python library\n",
    "\n",
    "In this section, we are submitting the simple task from above using the Python\n",
    "TES client `py-tes` (Figure 1C).\n",
    "\n",
    "**Figure 1C. Submitting tasks via the Python library.**\n",
    "\n",
    "![Figure 1C](images/figure_1C.svg)\n",
    "\n",
    "Usage is simple (from the [`py-tes` repository](https://github.com/ohsu-comp-bio/py-tes)):\n",
    "\n",
    "```python\n",
    "import tes\n",
    "\n",
    "task = tes.Task(\n",
    "    executors=[\n",
    "        tes.Executor(\n",
    "            image=\"alpine\",\n",
    "            command=[\"echo\", \"hello\"]\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "cli = tes.HTTPClient(\"http://funnel.example.com\", timeout=5)\n",
    "task_id = cli.create_task(task)\n",
    "res = cli.get_task(task_id)\n",
    "```\n",
    "\n",
    "To do so, we will execute Python script `task_submission.py`, which triggers\n",
    "the execution of our minimal task on the available TES instances and then\n",
    "checks the task state periodically until all tasks are in a finished state\n",
    "(one of `COMPLETE`, `EXECUTOR_ERROR`, `SYSTEM_ERROR`, or `CANCELLED`) or six\n",
    "checks (whichever occurs first)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26d45ea-2f1f-477a-82b2-ff091988a768",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "./task_submission.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff82e60-5f4c-4457-b952-a9fe12f3b2bb",
   "metadata": {},
   "source": [
    "Note that the `py-tes` library is used in various TES tools, including the\n",
    "[proTES](https://github.com/elixir-cloud-aai/proTES) gateway (see below) and\n",
    "the [cwl-tes](https://github.com/uniqueg/cwl-tes) and\n",
    "[Snakemake](https://snakemake.readthedocs.io/) workflow engines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf96900-7886-458f-9510-77a8406a6fb0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2. Sending tasks to TES gateway\n",
    "\n",
    "In this section, instead of sending tasks directly to the TES instances, we\n",
    "will send tasks to the [proTES](https://github.com/elixir-cloud-aai/proTES)\n",
    "gateway instead. The proTES, which acts both as a TES server and client, will\n",
    "then relay incoming tasks to the TES instances it knows about (this currently\n",
    "needs to be configured when deploying).\n",
    "\n",
    "To determine to which TES instance proTES relays a given task, two distribution\n",
    "logics have been implemented:\n",
    "- Random distribution\n",
    "- Distance-based distribution\n",
    "\n",
    "We will start off with randomly distributing tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e818e6-6519-4751-9194-a59ec3e7fc7b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Random task distribution\n",
    "\n",
    "In the random task distribution, for each incoming task, the known TES\n",
    "instances are randonly sorted and arranged into a ranked list. proTES will\n",
    "then attempt to forward the TES request to the first item in the list. If the\n",
    "request succeeds and a task identifier is returned, proTES will return its own\n",
    "task identifier to the client. If a task submission fails (e.g., because the\n",
    "TES instance is down), proTES will attempt to submit the task to the next TES\n",
    "instance in the list.\n",
    "\n",
    "After submitting a task, proTES will continue monitoring the execution of the\n",
    "task on the remote service in the background. In this way, the client can query\n",
    "the task status conveniently via proTES. Indeed, proTES is a complete TES API\n",
    "implementation, so the task list, task cancellation and service info endpoints\n",
    "are available as well. Thus, from the client's point of view, proTES is\n",
    "indistinguishable from a \"real\" TES instance, i.e., one that does the actual\n",
    "computation of the task as requested.\n",
    "\n",
    "For the random task distribution, we will use the minimal task definition from\n",
    "before, as it is sufficient to demonstrate the principle. Also, the random task\n",
    "distribution middleware is chosen by default, when proTES receives tasks\n",
    "without inputs. The service calls are depicted in Figure 2A.\n",
    "\n",
    "**Figure 2A. Task distribution via the proTES gateway.**\n",
    "\n",
    "![Figure 2A](images/figure_2A.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5e07e3-3e40-4816-ae54-8811366cdb6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "export PAYLOAD='{\"executors\":[{\"image\":\"alpine\",\"command\":[\"echo\",\"hello\"]}]}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df10633a-3827-4e77-b01a-d98c5a7a3f4b",
   "metadata": {},
   "source": [
    "Now let's set the gateway as the TES instance once and for all:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63be9437-3119-409d-94de-c97760f85b2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "export TES=\"$TES_GATEWAY\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b78ac5-5119-4a2f-ba56-eb4d55b377d2",
   "metadata": {},
   "source": [
    "Okay. Let's start off with a single task submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b061e06-5538-4206-8deb-c88284e3e332",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "echo \"Submitting task to TES gateway ($TES)...\"\n",
    "TASK_ID=$( \\\n",
    "    curl \\\n",
    "        --silent \\\n",
    "        --request \"POST\" \\\n",
    "        --header \"accept: application/json\" \\\n",
    "        --header \"Content-Type: application/json\" \\\n",
    "        --user \"${FUNNEL_SERVER_USER}:${FUNNEL_SERVER_PASSWORD}\" \\\n",
    "        --data \"$PAYLOAD\" \\\n",
    "        \"${TES%/}/ga4gh/tes/v1/tasks\" | \\\n",
    "    jq \".id\" - | \\\n",
    "    tr -d '\"'\n",
    ")\n",
    "if [ $TASK_ID == \"null\" ]; then\n",
    "    echo \"FAILED\"\n",
    "else\n",
    "    echo \"Task ID: $TASK_ID\"\n",
    "fi\n",
    "echo \"================================================================================\"\n",
    "echo \"DONE\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a62c51-9e47-4d65-aa13-dddf1b081228",
   "metadata": {},
   "source": [
    "And let's inspect the logs in detail:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61abcd0a-0e33-4445-ab9c-1c741b61625b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "VIEW=FULL\n",
    "echo \"Checking state of task '$TASK_ID' ($TES)...\"\n",
    "RESPONSE=$( \\\n",
    "    curl \\\n",
    "        --silent \\\n",
    "        --request \"GET\" \\\n",
    "        --header \"accept: application/json\" \\\n",
    "        --header \"Content-Type: application/json\" \\\n",
    "        --user \"${FUNNEL_SERVER_USER}:${FUNNEL_SERVER_PASSWORD}\" \\\n",
    "        \"${TES%/}/ga4gh/tes/v1/tasks/${TASK_ID}?view=${VIEW}\" \\\n",
    ")\n",
    "echo $RESPONSE | jq \".\"\n",
    "echo \"================================================================================\"\n",
    "echo \"DONE\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75339bfe-0ff2-41e8-91ae-1da86f806be5",
   "metadata": {},
   "source": [
    "Now, to ensure that we submit to different TES instances, let's send off a\n",
    "couple of task requests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac3b4b7-e951-4b6a-aeba-b85f926759a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "N_TASKS=8\n",
    "unset TASKS\n",
    "declare -A TASKS\n",
    "for key in {1..10}; do\n",
    "    echo \"Submitting task to TES gateway ($TES)...\"\n",
    "    TASK_ID=$( \\\n",
    "        curl \\\n",
    "            --silent \\\n",
    "            --request \"POST\" \\\n",
    "            --header \"accept: application/json\" \\\n",
    "            --header \"Content-Type: application/json\" \\\n",
    "            --user \"${FUNNEL_SERVER_USER}:${FUNNEL_SERVER_PASSWORD}\" \\\n",
    "            --data \"$PAYLOAD\" \\\n",
    "            \"${TES%/}/ga4gh/tes/v1/tasks\" | \\\n",
    "        jq \".id\" - | \\\n",
    "        tr -d '\"'\n",
    "    )\n",
    "    if [ $TASK_ID == \"null\" ]; then\n",
    "        echo \"FAILED\"\n",
    "    else\n",
    "        echo \"Task ID: $TASK_ID\"\n",
    "        TASKS[\"$TASK_ID\"]=\"$TES\"\n",
    "    fi\n",
    "    echo \"================================================================================\"\n",
    "done\n",
    "echo \"DONE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c123dd1-eedd-46c4-bcf6-adda3a18968a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for TASK_ID in \"${!TASKS[@]}\"; do\n",
    "    echo \"Checking state of task '$TASK_ID' ($TES)...\"\n",
    "    RESPONSE=$( \\\n",
    "        curl \\\n",
    "            --silent \\\n",
    "            --request \"GET\" \\\n",
    "            --header \"accept: application/json\" \\\n",
    "            --header \"Content-Type: application/json\" \\\n",
    "            --user \"${FUNNEL_SERVER_USER}:${FUNNEL_SERVER_PASSWORD}\" \\\n",
    "            \"${TES%/}/ga4gh/tes/v1/tasks/${TASK_ID}?view=BASIC\"\\\n",
    "    )\n",
    "    echo -n \"Task State: \"\n",
    "    echo $RESPONSE | jq \".state\"\n",
    "    echo -n \"Executed at: \"\n",
    "    echo $RESPONSE | jq '.logs[0].metadata.forwarded_to.url'\n",
    "    echo -n \"External task ID: \"\n",
    "    echo $RESPONSE | jq '.logs[0].metadata.forwarded_to.id'\n",
    "    echo \"================================================================================\"\n",
    "done\n",
    "echo \"DONE\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5ee0d5-1143-4217-bf5e-6d4d7655ce4e",
   "metadata": {},
   "source": [
    "### Distance-based task distribution\n",
    "\n",
    "With this distribution logic, proTES determines the approximate locations of\n",
    "all known TES instances and all input files for a task via their IP\n",
    "geolocations. For each TES instance, it then calculates the geographic distance\n",
    "to each input file and sums up the total distance for all files. Finally, it\n",
    "rank orders the available TES instances by total distance in ascending order.\n",
    "proTES then tries to forward the incoming task to the top entry of the resuling\n",
    "list, as described for the random distribution logic.\n",
    "\n",
    "In this way, the total geographic distance that files (but not bytes, as the\n",
    "input files sizes are unknown!) have to travel is minimized.\n",
    "\n",
    "Of course we will need a task with inputs. We will use our previous task again,\n",
    "as one input file should be sufficient to prove our point. It is also easier to\n",
    "check whether the distribution logic chose the right TES. To make it a bit more\n",
    "interesting, we will run the task several times, but each attempt with an input\n",
    "file at different location. The exercise is visualized in Figure 2B.\n",
    "\n",
    "**Figure 2B. Data flow for distance-based task distribution.** Service calls\n",
    "are as in Figure 2A and have been omitted for clarity.\n",
    "\n",
    "![Figure 2B](images/figure_2B.svg)\n",
    "\n",
    "Let's define our payload as before, but let's create one version per input\n",
    "file, with files hosted in the Czech Republic, Finland, Greece and Switzerland:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1def6c3b-dfaa-452c-9748-03e4b212ecfc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PAYLOAD_RAW='{\"name\":\"md5sum\",\"description\":\"calculate md5sum of input file and write to output file\",\"tags\":{\"project\":\"2023-ecp-f2f Demonstrator\",\"project_owner\":\"ELIXIR Cloud & AAI\"},\"executors\":[{\"command\":[\"md5sum\",\"/data/input\"],\"image\":\"alpine\",\"stdout\":\"/data/output\",\"workdir\":\"/data\"}],\"inputs\":[{\"url\":\"{{INPUT_FILE}}\",\"path\":\"/data/input\",\"type\":\"FILE\"}],\"outputs\":[{\"path\":\"/data/output\",\"url\":\"{{FTP_INSTANCE}}/2023-ecp-f2f/md5sum\",\"type\":\"FILE\"}],\"resources\":{\"cpu_cores\":1,\"disk_gb\":1,\"preemptible\":false,\"ram_gb\":1}}'\n",
    "PAYLOAD_TMP_1=$(sed \"s|{{FTP_INSTANCE}}|${FTP_INSTANCE%/}|\" <<< $PAYLOAD_RAW)\n",
    "PAYLOAD_TMP_2=$(sed \"s|ftp://|ftp://${FTP_USER}:${FTP_PASSWORD}@|g\" <<< $PAYLOAD_TMP_1)\n",
    "unset PAYLOADS\n",
    "declare -A PAYLOADS\n",
    "PAYLOADS[\"Czech Republic\"]=$(sed 's#{{INPUT_FILE}}#https://is.muni.cz/pics/design/r/znak_MU.png#' <<< $PAYLOAD_TMP_2)\n",
    "PAYLOADS[\"Finland\"]=$(sed 's#{{INPUT_FILE}}#https://www.csc.fi/o/csc-theme/images/csc-logo-teksti-fi.png#' <<< $PAYLOAD_TMP_2)\n",
    "PAYLOADS[\"Greece\"]=$(sed 's#{{INPUT_FILE}}#https://www.athenarc.gr/sites/default/files/picture1_0.png#' <<< $PAYLOAD_TMP_2)\n",
    "PAYLOADS[\"Switzerland\"]=$(sed 's#{{INPUT_FILE}}#https://www.sib.swiss//templates/sib/images/SIB_LogoQ_GBv.svg#' <<< $PAYLOAD_TMP_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bfc06b-938e-423e-be44-18c79ffb62b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "unset TASKS\n",
    "declare -A TASKS\n",
    "for COUNTRY in \"${!PAYLOADS[@]}\"; do\n",
    "    PAYLOAD=\"${PAYLOADS[$COUNTRY]}\"\n",
    "    echo \"Submitting task with input data in $COUNTRY ($TES)...\"\n",
    "    TASK_ID=$( \\\n",
    "        curl \\\n",
    "            --silent \\\n",
    "            --request \"POST\" \\\n",
    "            --header \"accept: application/json\" \\\n",
    "            --header \"Content-Type: application/json\" \\\n",
    "            --user \"${FUNNEL_SERVER_USER}:${FUNNEL_SERVER_PASSWORD}\" \\\n",
    "            --data \"$PAYLOAD\" \\\n",
    "            \"${TES%/}/ga4gh/tes/v1/tasks\" | \\\n",
    "        jq \".id\" - | \\\n",
    "        tr -d '\"'\n",
    "    )\n",
    "    if [ $TASK_ID == \"null\" ]; then\n",
    "        echo \"FAILED\"\n",
    "    else\n",
    "        echo \"Task ID: $TASK_ID\"\n",
    "        TASKS[\"$TASK_ID\"]=\"$COUNTRY\"\n",
    "    fi\n",
    "    echo \"================================================================================\"\n",
    "done\n",
    "echo \"DONE\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449a0336-c6bc-4378-a14b-7403ee9a4e83",
   "metadata": {},
   "source": [
    "It took a little while to do all the IP geolocation lookups. Let's see if it\n",
    "was worth the wait:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becf6d2a-a626-4def-93a9-a9b5291a42ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for TASK_ID in \"${!TASKS[@]}\"; do\n",
    "    export COUNTRY=\"${TASKS[$TASK_ID]}\"\n",
    "    echo \"Checking state of task '$TASK_ID' (input data in: $COUNTRY)...\"\n",
    "    RESPONSE=$( \\\n",
    "        curl \\\n",
    "            --silent \\\n",
    "            --request \"GET\" \\\n",
    "            --header \"accept: application/json\" \\\n",
    "            --header \"Content-Type: application/json\" \\\n",
    "            --user \"${FUNNEL_SERVER_USER}:${FUNNEL_SERVER_PASSWORD}\" \\\n",
    "            \"${TES%/}/ga4gh/tes/v1/tasks/${TASK_ID}?view=BASIC\"\\\n",
    "    )\n",
    "    echo -n \"Task State: \"\n",
    "    echo $RESPONSE | jq \".state\"\n",
    "    echo -n \"Executed at: \"\n",
    "    echo $RESPONSE | jq '.logs[0].metadata.forwarded_to.url'\n",
    "    echo -n \"External task ID: \"\n",
    "    echo $RESPONSE | jq '.logs[0].metadata.forwarded_to.id'\n",
    "    echo \"================================================================================\"\n",
    "done\n",
    "echo \"DONE\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9aed58-856c-40a8-8217-937e2f448525",
   "metadata": {},
   "source": [
    "You should see that each task was computed in the TES instance that is\n",
    "geographically closest to the location of the particular input data files.\n",
    "Nice!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbeba35b-b7e5-485e-8421-897a39916d2f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3. Executing workflows via the TES network\n",
    "\n",
    "In this section, we will demonstrate how a workflow engine with a TES backend\n",
    "can make use of the TES gateway to execute workflows on a network of TES\n",
    "instances.\n",
    "\n",
    "We will use the [`cwl-tes`](https://github.com/uniqueg/cwl-tes) workflow engine\n",
    "for running workflows written in the [Common Workflow Langauge\n",
    "(CWL)](https://www.commonwl.org/). `cwl-tes` extends the\n",
    "[`cwltool`](https://github.com/common-workflow-language/cwltool) CWL reference\n",
    "runner by adding a TES backend and cloud storage handlers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb7e8c5-919f-472b-be5d-dd72ead712b6",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Running CWL workflows with `cwl-tes`\n",
    "\n",
    "For the demo, we will run the \"hash splitter\" workflow (Figure 3A), a simple\n",
    "workflow with a scatter-gather step.\n",
    "\n",
    "**Figure 3A. DAG representation of the \"hash splitter\" workflow.**\n",
    "\n",
    "![Figure 3A](images/figure_3A.svg)\n",
    "\n",
    "**Figure 3B. Service calls and data flow for running the hash splitter\n",
    "workflow.** Numbers on labels for service calls, inputs and outputs match with\n",
    "the step numbers in Figure 3A.\n",
    "\n",
    "![Figure 3B](images/figure_3B.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0d161c-18c8-42cf-a419-f1fb21d4a909",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "unset TASK_IDS\n",
    "REMOTE_STORAGE_URL=$(sed \"s|ftp://|ftp://${FTP_USER}:${FTP_PASSWORD}@|\" <<< ${FTP_INSTANCE%})\n",
    "echo \"Starting hash splitter CWL workflow on cwl-tes via TES backend (TES gateway at ${TES_GATEWAY})...\"\n",
    "TASK_IDS=$(\n",
    "    cwl-tes \\\n",
    "         --remote-storage-url $REMOTE_STORAGE_URL \\\n",
    "         --tes \"${TES_GATEWAY}ga4gh/tes\" \\\n",
    "         --user $FUNNEL_SERVER_USER \\\n",
    "         --password $FUNNEL_SERVER_PASSWORD \\\n",
    "         --timeout \"30\" \\\n",
    "         --outdir \"results/\" \\\n",
    "         --tmpdir-prefix \"results/tmp_\" \\\n",
    "         --tmp-outdir-prefix \"results/tmp-out_\" \\\n",
    "         --leave-outputs \\\n",
    "         \"workflows/cwl_hashsplitter/hashsplitter-workflow.cwl\" \\\n",
    "         \"workflows/cwl_hashsplitter/hashsplitter-config.yml\" \\\n",
    "         2>&1 >/dev/null \\\n",
    "    | tee /dev/tty \\\n",
    "    | grep \"task id:\" \\\n",
    "    | sed -n 's/^.*task id: //p'\n",
    ")\n",
    "echo \"================================================================================\"\n",
    "echo \"DONE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b196f30-e76f-4ea6-ac80-cec10718d852",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for TASK_ID in $TASK_IDS; do\n",
    "    echo \"Checking state of task '$TASK_ID'...\"\n",
    "    RESPONSE=$( \\\n",
    "        curl \\\n",
    "            --silent \\\n",
    "            --request \"GET\" \\\n",
    "            --header \"accept: application/json\" \\\n",
    "            --header \"Content-Type: application/json\" \\\n",
    "            --user \"${FUNNEL_SERVER_USER}:${FUNNEL_SERVER_PASSWORD}\" \\\n",
    "            \"${TES_GATEWAY}/ga4gh/tes/v1/tasks/${TASK_ID}?view=BASIC\"\\\n",
    "    )\n",
    "    echo -n \"Task State: \"\n",
    "    echo $RESPONSE | jq \".state\"\n",
    "    echo -n \"Executed at: \"\n",
    "    echo $RESPONSE | jq '.logs[0].metadata.forwarded_to.url'\n",
    "    echo -n \"External task ID: \"\n",
    "    echo $RESPONSE | jq '.logs[0].metadata.forwarded_to.id'\n",
    "    echo \"================================================================================\"\n",
    "done\n",
    "echo \"DONE\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
